# DocQA ğŸ¤–
![image](https://media.licdn.com/dms/image/D4D12AQHp6b4DDVzSRw/article-cover_image-shrink_423_752/0/1693023472737?e=1698278400&v=beta&t=QuEWKDRtBEDtajq8CBDavfbrkQuj649zBheOBdgijec)

DocQA ğŸ¤– is a web application built using Streamlit ğŸ”¥ and the LangChain ğŸ¦œğŸ”— framework, allowing users to leverage the power of LLMs for Generative Question Answering. ğŸŒŸ

Read More Here ğŸ‘‰
[https://ai.plainenglish.io/ï¸-langchain-streamlit-llama-bringing-conversational-ai-to-your-local-machine-a1736252b172](https://www.linkedin.com/pulse/empowering-local-machines-langchain-streamlit-llama-unleashing-patel)

## Installation
To run the LangChain web application locally, follow these steps:

Clone this repository ğŸ”—
```
git clone https://github.com/TheJagStudio/DocQA.git
```
Create Virtual Environment and Install the required dependencies âš™ï¸
```
Run â¡ï¸ setup_env.bat 
```
Launch Streamlit App ğŸš€
```
Run â¡ï¸ run_app.bat
```
## Usage
Once you have the Streamlit  web application up and running, you can perform the following steps:

1. Upload the Text File.
2. Once the Text File is loaded as the Vector Store Database it will show a success alert "Document is Loaded".
3. Insert the question in "Ask" textbox and submit your question for LLM to generate the answer.

## Contributing
Contributions to this app are welcome! If you have any ideas, suggestions, or bug fixes, please feel free to open an issue or submit a pull request. We appreciate your contributions.

## License
This project is licensed under the MIT License.

ğŸ‰ Thank you ğŸ¤— Happy question answering! ğŸŒŸ
